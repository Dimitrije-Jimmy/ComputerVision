{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\programming\\anaconda3\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\programming\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2      # OpenCV for detection of objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"tracker.py\"\n",
    "import math\n",
    "\n",
    "\n",
    "class EuclideanDistTracker:\n",
    "    def __init__(self):\n",
    "        # Store the center positions of the objects\n",
    "        self.center_points = {}\n",
    "        # Keep the count of the IDs\n",
    "        # each time a new object id detected, the count will increase by one\n",
    "        self.id_count = 0\n",
    "\n",
    "\n",
    "    def update(self, objects_rect):\n",
    "        # Objects boxes and ids\n",
    "        objects_bbs_ids = []\n",
    "\n",
    "        # Get center point of new object\n",
    "        for rect in objects_rect:\n",
    "            x, y, w, h = rect\n",
    "            cx = (x + x + w) // 2\n",
    "            cy = (y + y + h) // 2\n",
    "\n",
    "            # Find out if that object was detected already\n",
    "            same_object_detected = False\n",
    "            for id, pt in self.center_points.items():\n",
    "                #dist = math.hypot(cx - pt[0], cy - pt[1])\n",
    "                distsq = (cx - pt[0])**2 + (cy - pt[1])**2\n",
    "\n",
    "                #if dist < 25:\n",
    "                if distsq < 625:\n",
    "                #if distsq < 10300:\n",
    "                    self.center_points[id] = (cx, cy)\n",
    "                    print(self.center_points)\n",
    "                    objects_bbs_ids.append([x, y, w, h, id])\n",
    "                    same_object_detected = True\n",
    "                    break\n",
    "\n",
    "            # New object is detected we assign the ID to that object\n",
    "            if same_object_detected is False:\n",
    "                self.center_points[self.id_count] = (cx, cy)\n",
    "                objects_bbs_ids.append([x, y, w, h, self.id_count])\n",
    "                self.id_count += 1\n",
    "\n",
    "        # Clean the dictionary by center points to remove IDS not used anymore\n",
    "        new_center_points = {}\n",
    "        for obj_bb_id in objects_bbs_ids:\n",
    "            _, _, _, _, object_id = obj_bb_id\n",
    "            center = self.center_points[object_id]\n",
    "            new_center_points[object_id] = center\n",
    "\n",
    "        # Update dictionary with IDs not used removed\n",
    "        self.center_points = new_center_points.copy()\n",
    "        return objects_bbs_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the video\n",
    "cap = cv2.VideoCapture(\"luxonis_task_video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object detection from Stable camera\n",
    "object_detector = cv2.createBackgroundSubtractorMOG2(history=100, varThreshold=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the video, has to be in same cell\n",
    "cap = cv2.VideoCapture(\"luxonis_task_video.mp4\")\n",
    "\n",
    "# Object detection from Stable camera\n",
    "object_detector = cv2.createBackgroundSubtractorMOG2(history=1000, varThreshold=500)\n",
    "\n",
    "# going through the frames and extracting it\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    mask = object_detector.apply(frame)\n",
    "    _, mask = cv2.threshold(mask, 254, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    #detections = []\n",
    "    \n",
    "    for cnt in contours:\n",
    "        cv2.drawContours(frame, [cnt], -1, (255, 0, 255), 2)\n",
    "\n",
    "    # This shows each frame\n",
    "    #cv2.imshow(\"roi\", roi)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Mask\", mask)\n",
    "\n",
    "    # key 27 is ESC, this will break the loop\n",
    "    key = cv2.waitKey(30)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (0,1) (1,196,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m     detections\u001b[38;5;241m.\u001b[39mappend([x, y, w, h])\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# 2. Object Tracking\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m boxes_ids \u001b[38;5;241m=\u001b[39m tracker\u001b[38;5;241m.\u001b[39mupdate(detections)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# we extract each object in this frame from the boxes_ids\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m box_id \u001b[38;5;129;01min\u001b[39;00m boxes_ids:\n",
      "Cell \u001b[1;32mIn[43], line 50\u001b[0m, in \u001b[0;36mObjectTracker.update\u001b[1;34m(self, detections)\u001b[0m\n\u001b[0;32m     47\u001b[0m predicted_positions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrackers[obj_id]\u001b[38;5;241m.\u001b[39mpredicted \u001b[38;5;28;01mfor\u001b[39;00m obj_id \u001b[38;5;129;01min\u001b[39;00m object_ids])\n\u001b[0;32m     49\u001b[0m detected_positions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([(d[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m d[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, d[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m d[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m detections])\n\u001b[1;32m---> 50\u001b[0m distance_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(predicted_positions[:, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m-\u001b[39m detected_positions[\u001b[38;5;28;01mNone\u001b[39;00m, :], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Solve the assignment problem using the Hungarian algorithm\u001b[39;00m\n\u001b[0;32m     53\u001b[0m row_ind, col_ind \u001b[38;5;241m=\u001b[39m linear_sum_assignment(distance_matrix)\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (0,1) (1,196,2) "
     ]
    }
   ],
   "source": [
    "# Version 2, with tracker\n",
    "\n",
    "# Create tracker object\n",
    "tracker = EuclideanDistTracker()\n",
    "\n",
    "#importing the video, has to be in same cell\n",
    "cap = cv2.VideoCapture(\"luxonis_task_video.mp4\")\n",
    "\n",
    "# Object detection from Stable camera\n",
    "object_detector = cv2.createBackgroundSubtractorMOG2(history=1000, varThreshold=100)\n",
    "\n",
    "# going through the frames and extracting it\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    mask = object_detector.apply(frame)\n",
    "\n",
    "    _, mask = cv2.threshold(mask, 254, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    detections = []\n",
    "    \n",
    "    for cnt in contours:\n",
    "        #cv2.drawContours(frame, [cnt], -1, (255, 0, 255), 2)\n",
    "\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        detections.append([x, y, w, h])\n",
    "\n",
    "    # 2. Object Tracking\n",
    "    boxes_ids = tracker.update(detections)\n",
    "\n",
    "    # we extract each object in this frame from the boxes_ids\n",
    "    for box_id in boxes_ids:\n",
    "        x, y, w, h, id = box_id\n",
    "\n",
    "        cv2.putText(frame, str(id), (x, y - 15), cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 0), 2)\n",
    "        \n",
    "        # Plots the rectangle of each bounding box\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "    \n",
    "\n",
    "    # This shows each frame\n",
    "    #cv2.imshow(\"roi\", roi)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Mask\", mask)\n",
    "\n",
    "    # key 27 is ESC, this will break the loop\n",
    "    key = cv2.waitKey(30)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (0,1) (1,5,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 61\u001b[0m\n\u001b[0;32m     58\u001b[0m detections \u001b[38;5;241m=\u001b[39m circle_detections \u001b[38;5;241m+\u001b[39m rect_detections\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Object Tracking\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m boxes_ids \u001b[38;5;241m=\u001b[39m tracker\u001b[38;5;241m.\u001b[39mupdate(detections)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# We extract each object in this frame from the boxes_ids\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m box_id \u001b[38;5;129;01min\u001b[39;00m boxes_ids:\n",
      "Cell \u001b[1;32mIn[43], line 50\u001b[0m, in \u001b[0;36mObjectTracker.update\u001b[1;34m(self, detections)\u001b[0m\n\u001b[0;32m     47\u001b[0m predicted_positions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrackers[obj_id]\u001b[38;5;241m.\u001b[39mpredicted \u001b[38;5;28;01mfor\u001b[39;00m obj_id \u001b[38;5;129;01min\u001b[39;00m object_ids])\n\u001b[0;32m     49\u001b[0m detected_positions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([(d[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m d[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, d[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m d[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m detections])\n\u001b[1;32m---> 50\u001b[0m distance_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(predicted_positions[:, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m-\u001b[39m detected_positions[\u001b[38;5;28;01mNone\u001b[39;00m, :], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Solve the assignment problem using the Hungarian algorithm\u001b[39;00m\n\u001b[0;32m     53\u001b[0m row_ind, col_ind \u001b[38;5;241m=\u001b[39m linear_sum_assignment(distance_matrix)\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (0,1) (1,5,2) "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Version 3, with improved detection\n",
    "\n",
    "# Create tracker object\n",
    "tracker = EuclideanDistTracker()\n",
    "\n",
    "# Importing the video, has to be in the same cell\n",
    "cap = cv2.VideoCapture(\"luxonis_task_video.mp4\")\n",
    "\n",
    "# Object detection from Stable camera\n",
    "object_detector = cv2.createBackgroundSubtractorMOG2(history=1000, varThreshold=100)\n",
    "\n",
    "def detect_circles(frame):\n",
    "    \"\"\"Detect circles in the frame using HoughCircles.\"\"\"\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.medianBlur(gray, 5)\n",
    "\n",
    "    # Detect circles using HoughCircles\n",
    "    circles = cv2.HoughCircles(blurred, cv2.HOUGH_GRADIENT, dp=1.2, minDist=20,\n",
    "                               param1=50, param2=30, minRadius=10, maxRadius=100)\n",
    "    detections = []\n",
    "    if circles is not None:\n",
    "        circles = np.round(circles[0, :]).astype(\"int\")\n",
    "        for (x, y, r) in circles:\n",
    "            detections.append([x-r, y-r, 2*r, 2*r])  # x, y, width, height\n",
    "    return detections\n",
    "\n",
    "def detect_rectangles(mask):\n",
    "    \"\"\"Detect rectangles using contours.\"\"\"\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    detections = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w > 20 and h > 20:  # Filter out small noise\n",
    "            detections.append([x, y, w, h])\n",
    "    return detections\n",
    "\n",
    "# Going through the frames and extracting them\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Apply background subtraction and threshold\n",
    "    mask = object_detector.apply(frame)\n",
    "    _, mask = cv2.threshold(mask, 254, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Detect circles\n",
    "    circle_detections = detect_circles(frame)\n",
    "    \n",
    "    # Detect rectangles (potential squares)\n",
    "    rect_detections = detect_rectangles(mask)\n",
    "\n",
    "    # Combine both detections\n",
    "    detections = circle_detections + rect_detections\n",
    "\n",
    "    # Object Tracking\n",
    "    boxes_ids = tracker.update(detections)\n",
    "\n",
    "    # We extract each object in this frame from the boxes_ids\n",
    "    for box_id in boxes_ids:\n",
    "        x, y, w, h, id = box_id\n",
    "        cv2.putText(frame, f'ID: {id}', (x, y - 15), cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 0), 2)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "\n",
    "    # Show each frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Mask\", mask)\n",
    "\n",
    "    # key 27 is ESC, this will break the loop\n",
    "    key = cv2.waitKey(30)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New tracker with Kalman Filter and Hungarian Algorithm\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "class KalmanFilter:\n",
    "    def __init__(self, x, y, w, h):\n",
    "        self.kalman = cv2.KalmanFilter(4, 2)\n",
    "        self.kalman.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)\n",
    "        self.kalman.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)\n",
    "        self.kalman.processNoiseCov = np.eye(4, dtype=np.float32) * 0.03\n",
    "\n",
    "        self.kalman.statePre = np.array([[x], [y], [0], [0]], np.float32)\n",
    "        self.kalman.statePost = np.array([[x], [y], [0], [0]], np.float32)\n",
    "\n",
    "        self.predicted = (x, y)\n",
    "        self.w = w\n",
    "        self.h = h\n",
    "        self.missed_frames = 0\n",
    "\n",
    "    def predict(self):\n",
    "        pred = self.kalman.predict()\n",
    "        self.predicted = (int(pred[0]), int(pred[1]))\n",
    "        return self.predicted\n",
    "\n",
    "    def correct(self, x, y):\n",
    "        self.kalman.correct(np.array([[x], [y]], np.float32))\n",
    "\n",
    "class ObjectTracker:\n",
    "    def __init__(self):\n",
    "        self.trackers = {}\n",
    "        self.id_count = 0\n",
    "\n",
    "    def update(self, detections):\n",
    "        # Predict the next position for each tracker\n",
    "        for obj_id, tracker in list(self.trackers.items()):\n",
    "            predicted_position = tracker.predict()\n",
    "            tracker.missed_frames += 1\n",
    "\n",
    "            # Remove trackers that have missed for too many frames\n",
    "            if tracker.missed_frames > 5:\n",
    "                del self.trackers[obj_id]\n",
    "\n",
    "        # If there are no trackers or detections, skip the distance matrix calculation\n",
    "        if len(self.trackers) == 0 or len(detections) == 0:\n",
    "            # If there are no trackers, initialize a new one for each detection\n",
    "            if len(self.trackers) == 0:\n",
    "                for detection in detections:\n",
    "                    self.trackers[self.id_count] = KalmanFilter(detection[0], detection[1], detection[2], detection[3])\n",
    "                    self.id_count += 1\n",
    "\n",
    "            # If there are no detections, return an empty list (no updates)\n",
    "            return []\n",
    "\n",
    "        # Get current tracker IDs and predicted positions\n",
    "        object_ids = list(self.trackers.keys())\n",
    "        predicted_positions = np.array([self.trackers[obj_id].predicted for obj_id in object_ids])\n",
    "\n",
    "        # Calculate the center of the detected positions\n",
    "        detected_positions = np.array([(d[0] + d[2] // 2, d[1] + d[3] // 2) for d in detections])\n",
    "\n",
    "        # Compute the distance matrix\n",
    "        distance_matrix = np.linalg.norm(predicted_positions[:, None] - detected_positions[None, :], axis=2)\n",
    "\n",
    "        # Solve the assignment problem using the Hungarian algorithm\n",
    "        row_ind, col_ind = linear_sum_assignment(distance_matrix)\n",
    "\n",
    "        assigned_ids = set()\n",
    "\n",
    "        for r, c in zip(row_ind, col_ind):\n",
    "            if distance_matrix[r, c] < 100:  # Threshold to consider a match\n",
    "                self.trackers[object_ids[r]].correct(detected_positions[c][0], detected_positions[c][1])\n",
    "                self.trackers[object_ids[r]].missed_frames = 0\n",
    "                assigned_ids.add(c)\n",
    "\n",
    "        # Add new trackers for unassigned detections\n",
    "        for i, detection in enumerate(detections):\n",
    "            if i not in assigned_ids:\n",
    "                self.trackers[self.id_count] = KalmanFilter(detection[0], detection[1], detection[2], detection[3])\n",
    "                self.id_count += 1\n",
    "\n",
    "        # Collect tracking results\n",
    "        results = []\n",
    "        for obj_id, tracker in self.trackers.items():\n",
    "            x, y = tracker.predicted\n",
    "            w = tracker.w\n",
    "            h = tracker.h\n",
    "            results.append([x - w // 2, y - h // 2, w, h, obj_id])\n",
    "\n",
    "        return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 4, Kalma Filter tracker integration\n",
    "\n",
    "# Main script with detection and tracking\n",
    "def detect_circles(frame):\n",
    "    \"\"\"Detect circles in the frame using HoughCircles.\"\"\"\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.medianBlur(gray, 5)\n",
    "\n",
    "    # Detect circles using HoughCircles\n",
    "    circles = cv2.HoughCircles(blurred, cv2.HOUGH_GRADIENT, dp=1.2, minDist=20,\n",
    "                               param1=50, param2=30, minRadius=10, maxRadius=100)\n",
    "    detections = []\n",
    "    if circles is not None:\n",
    "        circles = np.round(circles[0, :]).astype(\"int\")\n",
    "        for (x, y, r) in circles:\n",
    "            detections.append([x-r, y-r, 2*r, 2*r])  # x, y, width, height\n",
    "    return detections\n",
    "\n",
    "def detect_rectangles(mask):\n",
    "    \"\"\"Detect rectangles using contours.\"\"\"\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    detections = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w > 20 and h > 20:  # Filter out small noise\n",
    "            detections.append([x, y, w, h])\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legom\\AppData\\Local\\Temp\\ipykernel_17404\\120710923.py:23: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  self.predicted = (int(pred[0]), int(pred[1]))\n"
     ]
    }
   ],
   "source": [
    "# Create tracker object\n",
    "tracker = ObjectTracker()\n",
    "\n",
    "# Importing the video, has to be in the same cell\n",
    "cap = cv2.VideoCapture(\"luxonis_task_video.mp4\")\n",
    "\n",
    "# Object detection from stable camera\n",
    "object_detector = cv2.createBackgroundSubtractorMOG2(history=1000, varThreshold=100)\n",
    "\n",
    "# Going through the frames and extracting them\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Apply background subtraction and threshold\n",
    "    mask = object_detector.apply(frame)\n",
    "    _, mask = cv2.threshold(mask, 254, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Detect circles\n",
    "    circle_detections = detect_circles(frame)\n",
    "    \n",
    "    # Detect rectangles (potential squares)\n",
    "    rect_detections = detect_rectangles(mask)\n",
    "\n",
    "    # Combine both detections\n",
    "    detections = circle_detections + rect_detections\n",
    "\n",
    "    # Object Tracking\n",
    "    boxes_ids = tracker.update(detections)\n",
    "\n",
    "    # We extract each object in this frame from the boxes_ids\n",
    "    for box_id in boxes_ids:\n",
    "        x, y, w, h, id = box_id\n",
    "        cv2.putText(frame, f'ID: {id}', (x, y - 15), cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 0), 2)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "\n",
    "    # Show each frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Mask\", mask)\n",
    "\n",
    "    # key 27 is ESC, this will break the loop\n",
    "    key = cv2.waitKey(30)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legom\\AppData\\Local\\Temp\\ipykernel_17404\\120710923.py:23: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  self.predicted = (int(pred[0]), int(pred[1]))\n"
     ]
    }
   ],
   "source": [
    "# attempt with reducing noise\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define kernel for morphological operations\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "# Create tracker object (assuming you're using the Kalman tracker described earlier)\n",
    "tracker = ObjectTracker()\n",
    "\n",
    "cap = cv2.VideoCapture(\"luxonis_task_video.mp4\")\n",
    "\n",
    "# Object detection using a background subtractor\n",
    "object_detector = cv2.createBackgroundSubtractorMOG2(history=1000, varThreshold=100)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    mask = object_detector.apply(frame)\n",
    "\n",
    "    # Apply morphological operations to clean up the mask\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Threshold the mask\n",
    "    _, mask = cv2.threshold(mask, 254, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    detections = []\n",
    "\n",
    "    # Filter and process contours\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 500:  # Filter out small areas, adjust as needed\n",
    "            epsilon = 0.02 * cv2.arcLength(cnt, True)\n",
    "            approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
    "            if len(approx) == 4:\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                detections.append([x, y, w, h])\n",
    "            elif len(approx) > 8:  # If it looks like a circle\n",
    "                (x, y), radius = cv2.minEnclosingCircle(cnt)\n",
    "                x = int(x - radius)\n",
    "                y = int(y - radius)\n",
    "                w = h = int(2 * radius)\n",
    "                detections.append([x, y, w, h])\n",
    "\n",
    "    # Object tracking\n",
    "    boxes_ids = tracker.update(detections)\n",
    "\n",
    "    # Draw results\n",
    "    for box_id in boxes_ids:\n",
    "        x, y, w, h, obj_id = box_id\n",
    "        cv2.putText(frame, str(obj_id), (x, y - 15), cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 0), 2)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Mask\", mask)\n",
    "\n",
    "    key = cv2.waitKey(30)\n",
    "    if key == 27:  # ESC to break\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legom\\AppData\\Local\\Temp\\ipykernel_17404\\120710923.py:23: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  self.predicted = (int(pred[0]), int(pred[1]))\n"
     ]
    }
   ],
   "source": [
    "# attempt idk, provided with video\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Create tracker object\n",
    "tracker = ObjectTracker()\n",
    "\n",
    "cap = cv2.VideoCapture(\"luxonis_task_video.mp4\")\n",
    "\n",
    "# Define kernel for morphological operations\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "# Object detection using a background subtractor\n",
    "object_detector = cv2.createBackgroundSubtractorMOG2(history=1000, varThreshold=100)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    mask = object_detector.apply(frame)\n",
    "\n",
    "    # Apply morphological operations to clean up the mask\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Threshold the mask\n",
    "    _, mask = cv2.threshold(mask, 254, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours in the mask for square detection\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    detections = []\n",
    "\n",
    "    # Detect squares based on contours\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 500:  # Filter out small areas, adjust as needed\n",
    "            epsilon = 0.02 * cv2.arcLength(cnt, True)\n",
    "            approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
    "            if len(approx) == 4:\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                detections.append([x, y, w, h])\n",
    "\n",
    "    # Detect circles using HoughCircles\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, dp=1.2, minDist=50,\n",
    "                               param1=50, param2=30, minRadius=10, maxRadius=100)\n",
    "\n",
    "    if circles is not None:\n",
    "        circles = np.round(circles[0, :]).astype(\"int\")\n",
    "        for (x, y, r) in circles:\n",
    "            detections.append([x - r, y - r, 2 * r, 2 * r])\n",
    "\n",
    "    # Object tracking\n",
    "    boxes_ids = tracker.update(detections)\n",
    "\n",
    "    # Draw results\n",
    "    for box_id in boxes_ids:\n",
    "        x, y, w, h, obj_id = box_id\n",
    "        cv2.putText(frame, str(obj_id), (x, y - 15), cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 0), 2)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Mask\", mask)\n",
    "\n",
    "    key = cv2.waitKey(30)\n",
    "    if key == 27:  # ESC to break\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
