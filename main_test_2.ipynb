{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanFilter:\n",
    "    def __init__(self, x, y, w, h):\n",
    "        self.kalman = cv2.KalmanFilter(4, 2)\n",
    "        self.kalman.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)\n",
    "        self.kalman.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)\n",
    "        self.kalman.processNoiseCov = np.eye(4, dtype=np.float32) * 0.03\n",
    "\n",
    "        self.kalman.statePre = np.array([[x], [y], [0], [0]], np.float32)\n",
    "        self.kalman.statePost = np.array([[x], [y], [0], [0]], np.float32)\n",
    "\n",
    "        self.predicted = (x, y)\n",
    "        self.w = w\n",
    "        self.h = h\n",
    "        self.missed_frames = 0\n",
    "\n",
    "    def predict(self):\n",
    "        pred = self.kalman.predict()\n",
    "        self.predicted = (int(pred[0].item()), int(pred[1].item()))\n",
    "        return self.predicted\n",
    "\n",
    "    def correct(self, x, y):\n",
    "        self.kalman.correct(np.array([[x], [y]], np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectTracker:\n",
    "    def __init__(self):\n",
    "        self.trackers = {}\n",
    "        self.id_count = 0\n",
    "\n",
    "    def update(self, detections):\n",
    "        # Predict the next position for each tracker\n",
    "        for obj_id, tracker in list(self.trackers.items()):\n",
    "            predicted_position = tracker.predict()\n",
    "            tracker.missed_frames += 1\n",
    "\n",
    "            # Remove trackers that have missed for too many frames\n",
    "            if tracker.missed_frames > 10:  # Allow more missed frames for occlusion\n",
    "                del self.trackers[obj_id]\n",
    "\n",
    "        # Match detected objects with trackers\n",
    "        if len(detections) > 0:\n",
    "            object_ids = list(self.trackers.keys())\n",
    "            predicted_positions = np.array([self.trackers[obj_id].predicted for obj_id in object_ids])\n",
    "\n",
    "            detected_positions = np.array([(d[0] + d[2] // 2, d[1] + d[3] // 2) for d in detections])\n",
    "            if len(predicted_positions) > 0:\n",
    "                distance_matrix = np.linalg.norm(predicted_positions[:, None] - detected_positions[None, :], axis=2)\n",
    "\n",
    "                # Solve the assignment problem using the Hungarian algorithm\n",
    "                row_ind, col_ind = linear_sum_assignment(distance_matrix)\n",
    "\n",
    "                assigned_ids = set()\n",
    "\n",
    "                for r, c in zip(row_ind, col_ind):\n",
    "                    if distance_matrix[r, c] < 100:  # Threshold to consider a match\n",
    "                        self.trackers[object_ids[r]].correct(detected_positions[c][0], detected_positions[c][1])\n",
    "                        self.trackers[object_ids[r]].missed_frames = 0\n",
    "                        assigned_ids.add(c)\n",
    "\n",
    "                # Add new trackers for unassigned detections\n",
    "                for i, detection in enumerate(detections):\n",
    "                    if i not in assigned_ids:\n",
    "                        self.trackers[self.id_count] = KalmanFilter(detection[0], detection[1], detection[2], detection[3])\n",
    "                        self.id_count += 1\n",
    "\n",
    "        # Collect tracking results\n",
    "        results = []\n",
    "        for obj_id, tracker in self.trackers.items():\n",
    "            x, y = tracker.predicted\n",
    "            w = tracker.w\n",
    "            h = tracker.h\n",
    "            results.append([x - w // 2, y - h // 2, w, h, obj_id])\n",
    "\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_squares(mask):\n",
    "    \"\"\"\n",
    "    Square Detection:\n",
    "     Area Filter: The area > 1000 filter removes small, irrelevant contours. You may need to adjust this depending on the size of your squares.\n",
    "     Approximation Precision (epsilon): Controls how closely the contour approximation fits the detected shape. Adjust this to better match your square detection needs.\n",
    "     Morphological Operations: The kernel size and type (for cv2.morphologyEx) can be fine-tuned. A larger kernel can help close gaps or smooth noise, but too large may distort object shapes.\n",
    "    \"\"\"\n",
    "    # Find contours in the mask for square detection\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    detections = []\n",
    "\n",
    "    # Detect squares based on contours\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 500:  # Filter out small areas, adjust as needed\n",
    "            epsilon = 0.02 * cv2.arcLength(cnt, True)\n",
    "            approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
    "            if len(approx) == 4:\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                detections.append([x, y, w, h])\n",
    "\n",
    "    return detections\n",
    "\n",
    "def detect_circles(frame):\n",
    "    \"\"\"\n",
    "    Circle Detection (cv2.HoughCircles):\n",
    "     dp: The inverse ratio of the accumulator resolution to the image resolution. Start with 1.2, but you can adjust this slightly to see if it improves detection.\n",
    "     minDist: Minimum distance between the centers of detected circles. Increasing this value can prevent false positives from closely overlapping circles.\n",
    "     param1: Higher threshold for the Canny edge detector. This controls edge detection, which is crucial for accurate circle detection. Adjust if you find too many or too few circles.\n",
    "     param2: The accumulator threshold for the circle centers at the detection stage. Lowering this will detect more circles, but might also increase false positives.\n",
    "     minRadius and maxRadius: The minimum and maximum circle radius. Ensure these are set correctly based on the size of circles in your video.\n",
    "    \"\"\"\n",
    "    # Detect circles using HoughCircles\n",
    "    \n",
    "    detections = []\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, dp=1.2, minDist=50,\n",
    "                               param1=50, param2=30, minRadius=10, maxRadius=100)\n",
    "\n",
    "    if circles is not None:\n",
    "        circles = np.round(circles[0, :]).astype(\"int\")\n",
    "        for (x, y, r) in circles:\n",
    "            detections.append([x - r, y - r, 2 * r, 2 * r])\n",
    "\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tracker object\n",
    "tracker = ObjectTracker()\n",
    "\n",
    "cap = cv2.VideoCapture(\"luxonis_task_video.mp4\")\n",
    "\n",
    "# Define kernel for morphological operations\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "# Object detection using a background subtractor\n",
    "object_detector = cv2.createBackgroundSubtractorMOG2(history=1000, varThreshold=100)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    mask = object_detector.apply(frame)\n",
    "\n",
    "    # Apply morphological operations to clean up the mask\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Threshold the mask\n",
    "    _, mask = cv2.threshold(mask, 254, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    detections_squares = detect_squares(mask)\n",
    "    detections_circles = detect_circles(frame)\n",
    "\n",
    "    # Object tracking\n",
    "    boxes_ids = tracker.update(detections_squares + detections_circles)\n",
    "\n",
    "    # Draw results\n",
    "    for box_id in boxes_ids:\n",
    "        x, y, w, h, obj_id = box_id\n",
    "        cv2.putText(frame, str(obj_id), (x, y - 15), cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 0), 2)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "\n",
    "    cv2.imshow(\"Mask\", mask)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:  # ESC to break\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Should be a total of 21 objects I believe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectTracker:\n",
    "    def __init__(self):\n",
    "        self.trackers = {}\n",
    "        self.id_count = 0\n",
    "\n",
    "    def update(self, detections):\n",
    "        # Predict the next position for each tracker\n",
    "        for obj_id, tracker in list(self.trackers.items()):\n",
    "            tracker.predict()\n",
    "            tracker.missed_frames += 1\n",
    "\n",
    "            # Remove trackers that have missed for too many frames\n",
    "            if tracker.missed_frames > 10:  # Allow some frames for occlusion\n",
    "                del self.trackers[obj_id]\n",
    "\n",
    "        if len(detections) > 0:\n",
    "            object_ids = list(self.trackers.keys())\n",
    "            predicted_positions = np.array([self.trackers[obj_id].predicted for obj_id in object_ids])\n",
    "\n",
    "            detected_positions = np.array([(d[0] + d[2] // 2, d[1] + d[3] // 2) for d in detections])\n",
    "            if len(predicted_positions) > 0:\n",
    "                distance_matrix = np.linalg.norm(predicted_positions[:, None] - detected_positions[None, :], axis=2)\n",
    "\n",
    "                row_ind, col_ind = linear_sum_assignment(distance_matrix)\n",
    "\n",
    "                assigned_ids = set()\n",
    "\n",
    "                for r, c in zip(row_ind, col_ind):\n",
    "                    if distance_matrix[r, c] < 100:  # Threshold to consider a match\n",
    "                        self.trackers[object_ids[r]].correct(detected_positions[c][0], detected_positions[c][1])\n",
    "                        self.trackers[object_ids[r]].missed_frames = 0\n",
    "                        assigned_ids.add(c)\n",
    "\n",
    "                # Add new trackers for unassigned detections\n",
    "                for i, detection in enumerate(detections):\n",
    "                    if i not in assigned_ids:\n",
    "                        self.trackers[self.id_count] = KalmanFilter(detection[0], detection[1], detection[2], detection[3])\n",
    "                        self.id_count += 1\n",
    "            else:\n",
    "                # If no objects were tracked, create new trackers for all detections\n",
    "                for detection in detections:\n",
    "                    self.trackers[self.id_count] = KalmanFilter(detection[0], detection[1], detection[2], detection[3])\n",
    "                    self.id_count += 1\n",
    "\n",
    "        # Collect tracking results\n",
    "        results = []\n",
    "        for obj_id, tracker in self.trackers.items():\n",
    "            x, y = tracker.predicted\n",
    "            w = tracker.w\n",
    "            h = tracker.h\n",
    "            results.append([x - w // 2, y - h // 2, w, h, obj_id])\n",
    "\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your detection functions (already provided by you)\n",
    "def detect_squares(mask):\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    detections = []\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 1000:  # Filter out small areas, adjust as needed\n",
    "            epsilon = 0.02 * cv2.arcLength(cnt, True)\n",
    "            approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
    "            if len(approx) == 4:\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                detections.append([x, y, w, h])\n",
    "    return detections\n",
    "\n",
    "def detect_circles(frame):\n",
    "    detections = []\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, dp=1.2, minDist=50,\n",
    "                               param1=50, param2=30, minRadius=10, maxRadius=100)\n",
    "    if circles is not None:\n",
    "        circles = np.round(circles[0, :]).astype(\"int\")\n",
    "        for (x, y, r) in circles:\n",
    "            detections.append([x - r, y - r, 2 * r, 2 * r])\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legom\\AppData\\Local\\Temp\\ipykernel_31472\\1095347307.py:18: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  self.predicted = (int(pred[0]), int(pred[1]))\n"
     ]
    }
   ],
   "source": [
    "# Initialize the tracker\n",
    "tracker = ObjectTracker()\n",
    "\n",
    "# Video capture and processing\n",
    "cap = cv2.VideoCapture(\"luxonis_task_video.mp4\")\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "object_detector = cv2.createBackgroundSubtractorMOG2(history=1000, varThreshold=100)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    mask = object_detector.apply(frame)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    _, mask = cv2.threshold(mask, 254, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    detections_squares = detect_squares(mask)\n",
    "    detections_circles = detect_circles(frame)\n",
    "    detections = detections_squares + detections_circles\n",
    "\n",
    "    # Update tracker with detections\n",
    "    boxes_ids = tracker.update(detections)\n",
    "\n",
    "    # Draw results\n",
    "    for box_id in boxes_ids:\n",
    "        x, y, w, h, obj_id = box_id\n",
    "        cv2.putText(frame, str(obj_id), (x, y - 15), cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 0), 2)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "\n",
    "    cv2.imshow(\"Mask\", mask)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:  # ESC to break\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
